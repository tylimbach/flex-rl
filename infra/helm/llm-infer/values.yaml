image:
  repository: gcr.io/flex-rl/llm-infer
  tag: latest
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8080

resources:
  limits:
    nvidia.com/gpu: 1
    cpu: "4"
    memory: "16Gi"

env:
  - name: HUGGINGFACE_TOKEN
    valueFrom:
      secretKeyRef:
        name: hf-secret
        key: token

replicaCount: 1

autoscaling:
  enabled: false

podLabels: {}

serviceAccount:
  create: true
  name: llm-infer
  automount: true
